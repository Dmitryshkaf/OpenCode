{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from collections import defaultdict\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка модели YOLOv8\n",
    "model = YOLO('yolov9c.pt')\n",
    "\n",
    "# Список цветов для различных классов\n",
    "colors = [\n",
    "    (255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (0, 255, 255),\n",
    "    (255, 0, 255), (192, 192, 192), (128, 128, 128), (128, 0, 0), (128, 128, 0),\n",
    "    (0, 128, 0), (128, 0, 128), (0, 128, 128), (0, 0, 128), (72, 61, 139),\n",
    "    (47, 79, 79), (47, 79, 47), (0, 206, 209), (148, 0, 211), (255, 20, 147)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK№1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для обработки изображения\n",
    "def process_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    results = model(image)[0]\n",
    "    \n",
    "    # Получение оригинального изображения и результатов\n",
    "    image = results.orig_img\n",
    "    classes_names = results.names\n",
    "    classes = results.boxes.cls.cpu().numpy()\n",
    "    boxes = results.boxes.xyxy.cpu().numpy().astype(np.int32)\n",
    "\n",
    "    grouped_objects = {}\n",
    "\n",
    "    # Рисование рамок и группировка результатов\n",
    "    for class_id, box in zip(classes, boxes):\n",
    "        if class_id==0:    \n",
    "            class_name = classes_names[int(class_id)]\n",
    "            color = colors[int(class_id) % len(colors)]  \n",
    "            if class_name not in grouped_objects:\n",
    "                grouped_objects[class_name] = []\n",
    "                \n",
    "            x1, y1, x2, y2 = box\n",
    "            center_x = (x1 + x2) // 2\n",
    "            center_y = (y1 + y2) // 2\n",
    "            grouped_objects[class_name].append((box, (center_x, center_y)))\n",
    "            \n",
    "            cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(image, class_name, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "            \n",
    "    count_of_persons = len([el for el in classes if el == 0])\n",
    "     \n",
    "    cv2.putText(image, f\"Count of persons: {count_of_persons}\", (450,370), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    # Сохранение измененного изображения\n",
    "    new_image_path = os.path.splitext(image_path)[0] + '_yolo' + os.path.splitext(image_path)[1]\n",
    "    cv2.imwrite(new_image_path, image)\n",
    "\n",
    "    # Сохранение данных в текстовый файл\n",
    "    text_file_path = os.path.splitext(image_path)[0] + '_data.txt'\n",
    "    with open(text_file_path, 'w') as f:\n",
    "        for class_name, details in grouped_objects.items():\n",
    "            f.write(f\"{class_name}:\\n\")\n",
    "            for box, center in details:\n",
    "                f.write(f\"Coordinates: ({box[0]}, {box[1]}, {box[2]}, {box[3]}) Center: ({center[0]}, {center[1]})\\n\")\n",
    "    \n",
    "   \n",
    "    \n",
    "    print(f\"Count of persons: {count_of_persons}\")\n",
    "    print(f\"Processed {image_path}:\")\n",
    "    print(f\"Saved bounding-box image to {new_image_path}\")\n",
    "    print(f\"Saved data to {text_file_path}\")\n",
    "    return results, grouped_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res, objects = process_image('data/test_imgs/720x.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Получение центров баундбоксов людей и построение групп\n",
    "centers = np.array([objects['person'][el][1]  for el in range(len(objects['person']))])\n",
    "\n",
    "groups_of_persons= {}\n",
    "\n",
    "num_rectangles = centers.shape[0]\n",
    "distance_matrix = np.zeros((num_rectangles, num_rectangles))\n",
    "counter=-1\n",
    "for i in range(num_rectangles):\n",
    "    for j in range(num_rectangles):\n",
    "        if i != j:\n",
    "            distance_matrix[i, j] = np.linalg.norm(centers[i] - centers[j])\n",
    "            if distance_matrix[i,j]<100:\n",
    "                all_values = [item for sublist in groups_of_persons.values() for item in sublist]\n",
    "                if i not in all_values  and j not in all_values:\n",
    "                    counter+=1\n",
    "                    groups_of_persons.update({f\"Group №{counter}\" :[i,  j]})\n",
    "                else:\n",
    "                    groups_of_persons[f\"Group №{counter}\"].extend([i, j])\n",
    "#Получение людей в группах          \n",
    "unique_list = []\n",
    "for group in groups_of_persons.keys(): \n",
    "    persons_in_group = np.array(groups_of_persons[group])\n",
    "    unique_persons = np.unique(persons_in_group)\n",
    "    unique_list.append(unique_persons)\n",
    "# Получение координат баундбоксов\n",
    "list_of_coordinates=[]\n",
    "for group in range(len(unique_list)): \n",
    "    list_of_x=[]\n",
    "    list_of_y=[]\n",
    "    for num in unique_list[group]:\n",
    "        list_of_x.extend([objects[\"person\"][num][0][0], objects[\"person\"][num][0][2]])\n",
    "        list_of_y.extend([objects[\"person\"][num][0][1], objects[\"person\"][num][0][3]])\n",
    "    list_of_coordinates.append([list_of_x,list_of_y])\n",
    "        \n",
    "boundnoxes = []\n",
    "for coordinates in list_of_coordinates:\n",
    "    xmin, xmax = min(coordinates[0]), max(coordinates[0])\n",
    "    print(coordinates[0])\n",
    "    ymin, ymax = min(coordinates[1]), max(coordinates[1])\n",
    "    boundnoxes.append([xmin,ymin,xmax,ymax])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK№2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawing_boundboxes(image_path, boundnoxes, unique_list):\n",
    "    \n",
    "    image = cv2.imread(image_path)\n",
    "    class_name = \"Group\"\n",
    "    color = colors[int(2) % len(colors)] \n",
    "    grouped_objects = {}\n",
    "    \n",
    "    for box in boundnoxes:\n",
    "        x1, y1, x2, y2 = box\n",
    "        \n",
    "        grouped_objects[class_name] = []\n",
    "        grouped_objects[class_name].append(box)\n",
    "        \n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.putText(image, class_name, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "     \n",
    "    count_of_groups = len(boundnoxes)\n",
    "    count_of_persons = [len(unic) for unic in unique_list]\n",
    "    \n",
    "    cv2.putText(image, f\"Count of Groups: {count_of_groups}\", (450,320), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "    cv2.putText(image, f\"Count of People in Group: {count_of_persons}\", (450,350), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "    \n",
    "    new_image_path = os.path.splitext(image_path)[0] + '_grouped' + os.path.splitext(image_path)[1]\n",
    "    cv2.imwrite(new_image_path, image)\n",
    "\n",
    "    \n",
    "    text_file_path = os.path.splitext(image_path)[0] + '_data2.txt'\n",
    "    with open(text_file_path, 'w') as f:\n",
    "        for class_name, details in grouped_objects.items():\n",
    "            f.write(f\"{class_name}:\\n\")\n",
    "            for box in details:\n",
    "                f.write(f\"Coordinates: ({box[0]}, {box[1]}, {box[2]}, {box[3]})\\n\")\n",
    "\n",
    "    print(f\"Count of groups: {count_of_groups}\")\n",
    "    print(f\"Processed {image_path}:\")\n",
    "    print(f\"Saved bounding-box image to {new_image_path}\")\n",
    "    print(f\"Saved data to {text_file_path}\")\n",
    "    return grouped_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_res = drawing_boundboxes('data/test_imgs/720x_yolo.png', boundnoxes, unique_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK№3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Model for helmets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()  \n",
    "\n",
    "data_path = os.path.join(current_dir, 'data.yaml')\n",
    "model = YOLO(os.path.join(current_dir, 'yolov9c.pt'))\n",
    "epochs = 250\n",
    "batch = 10\n",
    "image_size = 640\n",
    "\n",
    "if __name__ =='__main__':\n",
    "    results = model.train(data = data_path,\n",
    "                          epochs = epochs,\n",
    "                          batch = batch,\n",
    "                          imgsz = image_size,\n",
    "                          name = 'red',\n",
    "                          device = 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = YOLO('detect/final/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_inside(box1, box2):\n",
    "    \"\"\"\n",
    "    проверяет, находится ли box2!!! внутри box1!!!\n",
    "    \"\"\"\n",
    "    x1_1, y1_1, x2_1, y2_1 = box1\n",
    "    x1_2, y1_2, x2_2, y2_2 = box2\n",
    "\n",
    "    return (x1_1 <= x1_2 <= x2_1 and y1_1 <= y1_2 <= y2_1) or (x1_1 <= x2_2 <= x2_1 and y1_1 <= y2_2 <= y2_1)\n",
    "    \n",
    "def process_with_helmets(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    results = model(image)[0]\n",
    "    \n",
    "    image = results.orig_img\n",
    "    classes_names = results.names\n",
    "    classes = results.boxes.cls.cpu().numpy()\n",
    "    boxes = results.boxes.xyxy.cpu().numpy().astype(np.int32)\n",
    "    \n",
    "    helmets_results = model1(image)[0]\n",
    "    image = helmets_results.orig_img\n",
    "    helmet_classes_names = helmets_results.names\n",
    "    helmet_classes = helmets_results.boxes.cls.cpu().numpy()\n",
    "    helmet_boxes = helmets_results.boxes.xyxy.cpu().numpy().astype(np.int32)\n",
    "\n",
    "    grouped_objects = {}\n",
    "    unique_helmet_boxes = set()\n",
    "    count_of_helmets =0\n",
    "    \n",
    "    for class_id, box in zip(classes, boxes):\n",
    "        if class_id == 0:\n",
    "            class_name = classes_names[int(class_id)]\n",
    "            color = colors[int(class_id) % len(colors)]\n",
    "            if class_name not in grouped_objects:\n",
    "                grouped_objects[class_name] = []\n",
    "                \n",
    "            x1, y1, x2, y2 = box\n",
    "            center_x = (x1 + x2) // 2\n",
    "            center_y = (y1 + y2) // 2\n",
    "            grouped_objects[class_name].append((box, (center_x, center_y)))\n",
    "            \n",
    "            for h_class_id, h_box in zip(helmet_classes, helmet_boxes):\n",
    "                if h_class_id == 0:\n",
    "                    h_class_name = helmet_classes_names[int(h_class_id)]\n",
    "                    h_color = colors[int(h_class_id) % len(colors)+1]\n",
    "                    if is_inside(box, h_box):\n",
    "                        h_box_tuple = tuple(h_box)\n",
    "                        if h_box_tuple not in unique_helmet_boxes:\n",
    "                            if h_class_name not in grouped_objects:\n",
    "                                grouped_objects[h_class_name] = []\n",
    "                            h_x1, h_y1, h_x2, h_y2 = h_box\n",
    "                            center_h_x = (h_x1 + h_x2) // 2\n",
    "                            center_h_y = (h_y1 + h_y2) // 2\n",
    "                            grouped_objects[h_class_name].append((h_box, (center_h_x, center_h_y)))\n",
    "\n",
    "                            count_of_helmets += 1\n",
    "                            unique_helmet_boxes.add(h_box_tuple)\n",
    "\n",
    "                            cv2.rectangle(image, (h_x1, h_y1), (h_x2, h_y2), h_color, 2)\n",
    "                            cv2.putText(image, h_class_name, (h_x1, h_y1 - 3), cv2.FONT_HERSHEY_SIMPLEX, 0.4, h_color, 1)\n",
    "            \n",
    "            cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(image, class_name, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "            \n",
    "    count_of_persons = len([el for el in classes if el == 0])\n",
    "     \n",
    "    cv2.putText(image, f\"Count of persons: {count_of_persons}\", (440, 365), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "    cv2.putText(image, f\"Count of people in helmets: {count_of_helmets}\", (440, 380), cv2.FONT_HERSHEY_SIMPLEX, 0.5, h_color, 2)\n",
    "    cv2.putText(image, f\"Count of people without helmets: {count_of_persons - count_of_helmets}\", (435, 395), cv2.FONT_HERSHEY_SIMPLEX, 0.5, colors[2], 2)\n",
    "\n",
    "    new_image_path = os.path.splitext(image_path)[0] + '_yolo_helmet' + os.path.splitext(image_path)[1]\n",
    "    cv2.imwrite(new_image_path, image)\n",
    "    print(grouped_objects)\n",
    "\n",
    "    text_file_path = os.path.splitext(image_path)[0] + '_data_helmet.txt'\n",
    "    with open(text_file_path, 'w') as f:\n",
    "        for class_name, details in grouped_objects.items():\n",
    "            f.write(f\"{class_name}:\\n\")\n",
    "            for box, center in details:\n",
    "                f.write(f\"Coordinates: ({box[0]}, {box[1]}, {box[2]}, {box[3]}) Center: ({center[0]}, {center[1]})\\n\")\n",
    "    \n",
    "    print(f\"Count of persons: {count_of_persons}\")\n",
    "    print(f\"Processed {image_path}:\")\n",
    "    print(f\"Saved bounding-box image to {new_image_path}\")\n",
    "    print(f\"Saved data to {text_file_path}\")\n",
    "    return results, grouped_objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK№1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_processing(image):\n",
    "        \n",
    "    results = model.track(image, persist=True, tracker=\"bytetrack.yaml\")[0]\n",
    "    image = results.orig_img\n",
    "    classes_names = results.names\n",
    "    classes = results.boxes.cls.cpu().numpy()\n",
    "    boxes = results.boxes.xyxy.cpu().numpy().astype(np.int32)\n",
    "    \n",
    "    helmets_results = model1.track(image, persist=True, tracker=\"bytetrack.yaml\")[0]\n",
    "    \n",
    "    image = helmets_results.orig_img\n",
    "    helmet_classes_names = helmets_results.names\n",
    "    helmet_classes = helmets_results.boxes.cls.cpu().numpy()\n",
    "    helmet_boxes = helmets_results.boxes.xyxy.cpu().numpy().astype(np.int32)\n",
    "\n",
    "    grouped_objects = defaultdict(list)\n",
    "    unique_helmet_boxes = set()\n",
    "    \n",
    "    for class_id, box, conf, id in zip(classes, boxes, results.boxes.conf, results.boxes.id):\n",
    "        if class_id == 0 and conf > 0.35:\n",
    "            class_name = classes_names[int(class_id)]\n",
    "            color = colors[int(class_id) % len(colors)]\n",
    "            if class_name not in grouped_objects:\n",
    "                grouped_objects[class_name] = []\n",
    "                \n",
    "            x1, y1, x2, y2 = box\n",
    "            center_x = (x1 + x2) // 2\n",
    "            center_y = (y1 + y2) // 2\n",
    "            grouped_objects[class_name].append((box, (center_x, center_y)))\n",
    "            \n",
    "            for h_class_id, h_box, h_conf in zip(helmet_classes, helmet_boxes, helmets_results.boxes.conf):\n",
    "                if is_inside(box, h_box) and h_conf > 0.45:\n",
    "                    if h_class_id == 0:\n",
    "                        h_class_name = helmet_classes_names[int(h_class_id)]\n",
    "                        h_color = colors[int(h_class_id) % len(colors) + 1]\n",
    "                        \n",
    "                        h_box_tuple = tuple(h_box)\n",
    "                        if h_box_tuple not in unique_helmet_boxes:\n",
    "                            grouped_objects[h_class_name].append((h_box, (center_x, center_y)))\n",
    "\n",
    "                            unique_helmet_boxes.add(h_box_tuple)\n",
    "\n",
    "                            cv2.rectangle(image, (h_box[0], h_box[1]), (h_box[2], h_box[3]), h_color, 2)\n",
    "                            cv2.putText(image, h_class_name, (h_box[0], h_box[1] - 3), cv2.FONT_HERSHEY_SIMPLEX, 0.4, h_color, 1)\n",
    "            \n",
    "            cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(image,f\"id:{id} \" + class_name, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "            \n",
    "    count_of_persons = len([el for el in classes if el == 0])\n",
    "    count_of_helmets = len(grouped_objects.get('helmet', []))\n",
    "     \n",
    "    cv2.putText(image, f\"Count of persons: {count_of_persons}\", (1350, 800), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "    cv2.putText(image, f\"Count of people in helmets: {count_of_helmets}\", (1350, 840), cv2.FONT_HERSHEY_SIMPLEX, 1, colors[1], 2)\n",
    "    cv2.putText(image, f\"Count of people without helmets: {count_of_persons - count_of_helmets}\", (1350, 880), cv2.FONT_HERSHEY_SIMPLEX, 1, colors[2], 2)\n",
    "\n",
    "    return results, grouped_objects, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"data/test_imgs/video_tracking.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Проверка успешного открытия видео\n",
    "if not cap.isOpened():\n",
    "    print(f\"Ошибка открытия {video_path}\")\n",
    "    exit()\n",
    "\n",
    "# Получение FPS видео\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Настройка VideoWriter для сохранения выходного видео\n",
    "output_video_path = 'data/test_imgs/video_tracking_yolo.mp4'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "track_history = defaultdict(lambda: [])\n",
    "unique_ids = set()\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if not success:\n",
    "        print(\"Конец видео\")\n",
    "        break\n",
    "\n",
    "    # Обработка кадра с использованием функции video_processing\n",
    "    results, objects, annotated_frame = video_processing(frame)\n",
    "    if results and results.boxes and results.boxes.id is not None:\n",
    "        \n",
    "        boxes = results.boxes.xyxy.cpu().numpy()\n",
    "        track_ids = results.boxes.id.int().cpu().tolist()\n",
    "\n",
    "        helmet_boxes = {tuple(h_box) for h_box, _ in objects['helmet']}\n",
    "        unique_ids.update(track_ids)\n",
    "\n",
    "        for box, track_id in zip(boxes, track_ids):\n",
    "            if all(not is_inside(box, np.array(h_box)) for h_box in helmet_boxes):\n",
    "                x1, y1, x2, y2 = box\n",
    "                center_x = (x1 + x2) // 2\n",
    "                center_y = (y1 + y2) // 2\n",
    "\n",
    "                if track_history[track_id]:\n",
    "                    last_center = track_history[track_id][-1]\n",
    "                    distance = math.dist((center_x, center_y), last_center)\n",
    "                    if distance > 100:\n",
    "                        track_history[track_id] = []\n",
    "\n",
    "                track_history[track_id].append((center_x, center_y))  # добавление координат центра объекта в историю\n",
    "                if len(track_history[track_id]) > 30:  # ограничение длины истории до 30 кадров\n",
    "                    track_history[track_id].pop(0)\n",
    "\n",
    "                points = np.array(track_history[track_id], dtype=np.int32).reshape((-1, 1, 2))\n",
    "                cv2.polylines(annotated_frame, pts=[points], isClosed=False, color=(230, 230, 230), thickness=2)\n",
    "\n",
    "        cv2.putText(annotated_frame, f\"Count of track ids: {len(unique_ids)}\", (1350, 920), cv2.FONT_HERSHEY_SIMPLEX, 1, colors[1], 2)\n",
    "\n",
    "        out.write(annotated_frame)\n",
    "    else:\n",
    "        out.write(frame) \n",
    "\n",
    "cap.release()\n",
    "out.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "<Pytorch- GPU>",
   "language": "python",
   "name": "pytorch-cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
